{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/alfa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "import json\n",
    "import re\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will clean our text from data that is not important so that has no weight \n",
    "def clean_text(tweet):\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ## START CODE\n",
    "   \n",
    "    tweet = tweet.lower() # Transform in lowercase\n",
    "\n",
    "    tweet = re.sub(r'@[a-zA-Z]+', '', tweet) # Here we remove the mentions in the tweet ex: @canodep\n",
    "    tweet = re.sub(r\"\\B#([a-z0-9]{2,})(?![~!@#$%^&*()=+_`\\-\\|\\/'\\[\\]\\{\\}]|[?.,]*\\w)\", '', tweet) # Here we remove the hashtags, because we will treat it later\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet) # Here we remove punctuation marks\n",
    "    tweet = re.sub(r'http\\S+', '',tweet) # Remove http and https\n",
    "    tweet = tweet.split() # Tokenize the text to get a list of terms\n",
    "\n",
    "    tweet = [word for word in tweet if word not in stop_words]  # eliminate the stopwords\n",
    "    tweet = [stemmer.stem(word) for word in tweet] # Perform stemming \n",
    "    ## END CODE    \n",
    "    return tweet\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path = 'data/tw_hurricane_data.json'\n",
    "tweets_title = 'data/tweet_document_ids_map.csv'\n",
    "\n",
    "tweets_id_title = {}\n",
    "\n",
    "with open(tweets_title) as fp:\n",
    "    lines = fp.readlines()\n",
    "\n",
    "\n",
    "for l in lines:\n",
    "    l = l.strip().split(\"\\t\")\n",
    "    tweets_id_title[int(l[1])] =  l[0]\n",
    "\n",
    "\n",
    "tweets = []\n",
    "lines = []\n",
    "\n",
    "for line in open(docs_path, 'r'):\n",
    "    lines.append(line)\n",
    "    #media = json.loads(line).get('entities').get('media')\n",
    "    tweets.append({\n",
    "        'id' : int(json.loads(line).get('id')),\n",
    "        'title' : tweets_id_title[int(json.loads(line).get('id'))],\n",
    "        'text': clean_text(json.loads(line).get('full_text')),\n",
    "        'username' : json.loads(line).get('user').get('screen_name'),\n",
    "        'date' : json.loads(line).get('created_at'),\n",
    "        'hashtag' : list(map(lambda hashtag:  hashtag.get('text'),  json.loads(line).get('entities').get('hashtags'))),\n",
    "        'like' : json.loads(line).get('favorite_count'),\n",
    "        'rt' : json.loads(line).get('retweet_count'),\n",
    "        'URL' : 'https://twitter.com/' + json.loads(line).get('user').get('screen_name') + \"/status/\" + str(json.loads(line).get('id'))\n",
    "    }) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Tweets: 4000\n",
      "Example tweet: {'id': 1575916474790821889, 'title': 'doc_121', 'text': ['hurrican', 'ian', 'updat', '2', 'pm', 'shallott', 'north', 'carolina'], 'username': 'johndalytv', 'date': 'Fri Sep 30 18:32:21 +0000 2022', 'hashtag': ['HurricaneIan', 'ShallotteNorthCarolina', 'RiversEdge', 'DalyReport', 'BrunswickCounty', 'NorthCarolina', 'MyrtleBeach', 'VideoMarketing', 'JohnDaly', 'ShotOnTheiPhone', 'Wilmington'], 'like': 0, 'rt': 0, 'URL': 'https://twitter.com/johndalytv/status/1575916474790821889'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of Tweets: {}\".format(len(tweets)))\n",
    "\n",
    "print(\"Example tweet: {}\".format(tweets[120]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
