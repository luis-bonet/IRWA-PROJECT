{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lucho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "import json\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet': 'Our list has expanded: \\nCommunity foundations across #Florida have set up relief funds to help those impacted by #HurricaneIan, take action now and share.\\n@CFSarasota\\n@ManateeCF\\n@CollierCFFL \\n@GiveCF\\n@MiamiFoundation\\nhttps://t.co/0uUi16FITA', 'date': 'Fri Sep 30 17:51:40 +0000 2022', 'hashtag': [{'text': 'Florida', 'indices': [53, 61]}, {'text': 'HurricaneIan', 'indices': [113, 126]}], 'like': 2}\n"
     ]
    }
   ],
   "source": [
    "docs_path = 'data/tw_hurricane_data.json'\n",
    "tweets = []\n",
    "lines = []\n",
    "\n",
    "for line in open(docs_path, 'r'):\n",
    "    lines.append(line)\n",
    "    entities = json.loads(line).get('entities')\n",
    "    tweets.append({\n",
    "        'tweet':json.loads(line).get('full_text'),\n",
    "        'date' : json.loads(line).get('created_at'),\n",
    "        'hashtag' : json.loads(line).get('entities').get('hashtags'), #Si aÃ±adimos .get('text') obtenemos solo info del hashtag\n",
    "        'like' : json.loads(line).get('favorite_count'),\n",
    "        'rt' : json.loads(line).get('retweet_count'),\n",
    "        'URL' : json.loads(line).get('created_at')\n",
    "    }) #Here we get only the text from the tweets in json document\n",
    "print(tweets[1000])\n",
    "\n",
    "#print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Wikipedia articles in the corpus: 4000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of Wikipedia articles in the corpus: {}\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will clean our text from data that is not important so that has no weight \n",
    "def clean_text(tweets):\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ## START CODE\n",
    "    tweets =  tweets.lower() ## Transform in lowercase\n",
    "    tweets =  tweets.split() ## Tokenize the text to get a list of terms\n",
    "    tweets = [word for word in tweets if word not in stop_words]  ##eliminate the stopwords (HINT: use List Comprehension)\n",
    "    tweets = [stemmer.stem(word) for word in tweets] ## perform stemming (HINT: use List Comprehension)\n",
    "    ## END CODE    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heart', 'go', 'affect', '#hurricaneian.', 'wish', 'everyon', 'road', 'current', 'brave', 'condit', 'safe', 'travels.', 'ðŸ’™']\n"
     ]
    }
   ],
   "source": [
    "print(clean_text(tweets[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
